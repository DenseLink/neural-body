{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Packages and Setup Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Allow printing of large numpy arrays.\n",
    "# import sys\n",
    "# import numpy\n",
    "# numpy.set_printoptions(threshold=sys.maxsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove max columns and row limit on pandas\n",
    "pd.options.display.max_columns = None\n",
    "pd.options.display.max_rows = 50000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Position Data and Display for the Given Simulation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the binary numpy files storing the acceleration, velocity, position, and mass for \n",
    "# every body at every time step.\n",
    "data_folder = \"input_data/\"\n",
    "\n",
    "# a_raw = np.load(data_folder + \"a.npy\")\n",
    "# v_raw = np.load(data_folder + \"v.npy\")\n",
    "# x_raw = np.load(data_folder + \"x.npy\")\n",
    "# m_raw = np.load(data_folder + \"m.npy\")\n",
    "a_df = pd.read_pickle(data_folder + 'a.pkl')\n",
    "v_df = pd.read_pickle(data_folder + 'v.pkl')\n",
    "p_df = pd.read_pickle(data_folder + 'p.pkl')\n",
    "d_df = pd.read_pickle(data_folder + 'd.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time_step</th>\n",
       "      <th>body_name</th>\n",
       "      <th>dis_x</th>\n",
       "      <th>dis_y</th>\n",
       "      <th>dis_z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>sun</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>5.294462e-04</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>mercury</td>\n",
       "      <td>4.740000e+06</td>\n",
       "      <td>-3.959744e+02</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>venus</td>\n",
       "      <td>3.500000e+06</td>\n",
       "      <td>-1.133869e+02</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>earth</td>\n",
       "      <td>2.980000e+06</td>\n",
       "      <td>-5.931664e+01</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>mars</td>\n",
       "      <td>2.410000e+06</td>\n",
       "      <td>-2.555951e+01</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>sat1</td>\n",
       "      <td>7.800000e+05</td>\n",
       "      <td>-5.931321e+19</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2</td>\n",
       "      <td>sun</td>\n",
       "      <td>1.796815e-08</td>\n",
       "      <td>1.058758e-03</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>mercury</td>\n",
       "      <td>4.740000e+06</td>\n",
       "      <td>-7.919488e+02</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>venus</td>\n",
       "      <td>3.500000e+06</td>\n",
       "      <td>-2.267739e+02</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2</td>\n",
       "      <td>earth</td>\n",
       "      <td>2.980000e+06</td>\n",
       "      <td>-1.186333e+02</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2</td>\n",
       "      <td>mars</td>\n",
       "      <td>2.410000e+06</td>\n",
       "      <td>-5.111903e+01</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2</td>\n",
       "      <td>sat1</td>\n",
       "      <td>7.800000e+05</td>\n",
       "      <td>-5.931321e+19</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>3</td>\n",
       "      <td>sun</td>\n",
       "      <td>5.390445e-08</td>\n",
       "      <td>1.588070e-03</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>3</td>\n",
       "      <td>mercury</td>\n",
       "      <td>4.740000e+06</td>\n",
       "      <td>-1.187923e+03</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>3</td>\n",
       "      <td>venus</td>\n",
       "      <td>3.500000e+06</td>\n",
       "      <td>-3.401608e+02</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    time_step body_name         dis_x         dis_y  dis_z\n",
       "0           1       sun  0.000000e+00  5.294462e-04    0.0\n",
       "1           1   mercury  4.740000e+06 -3.959744e+02    0.0\n",
       "2           1     venus  3.500000e+06 -1.133869e+02    0.0\n",
       "3           1     earth  2.980000e+06 -5.931664e+01    0.0\n",
       "4           1      mars  2.410000e+06 -2.555951e+01    0.0\n",
       "5           1      sat1  7.800000e+05 -5.931321e+19    0.0\n",
       "6           2       sun  1.796815e-08  1.058758e-03    0.0\n",
       "7           2   mercury  4.740000e+06 -7.919488e+02    0.0\n",
       "8           2     venus  3.500000e+06 -2.267739e+02    0.0\n",
       "9           2     earth  2.980000e+06 -1.186333e+02    0.0\n",
       "10          2      mars  2.410000e+06 -5.111903e+01    0.0\n",
       "11          2      sat1  7.800000e+05 -5.931321e+19    0.0\n",
       "12          3       sun  5.390445e-08  1.588070e-03    0.0\n",
       "13          3   mercury  4.740000e+06 -1.187923e+03    0.0\n",
       "14          3     venus  3.500000e+06 -3.401608e+02    0.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_df.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attempt to Convert All Data to Pandas Multi-Index Dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Will be using groupby() to create a new MultiIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>dis_x</th>\n",
       "      <th>dis_y</th>\n",
       "      <th>dis_z</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time_step</th>\n",
       "      <th>body_name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">1</th>\n",
       "      <th>earth</th>\n",
       "      <td>2.980000e+06</td>\n",
       "      <td>-5.931664e+01</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mars</th>\n",
       "      <td>2.410000e+06</td>\n",
       "      <td>-2.555951e+01</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mercury</th>\n",
       "      <td>4.740000e+06</td>\n",
       "      <td>-3.959744e+02</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sat1</th>\n",
       "      <td>7.800000e+05</td>\n",
       "      <td>-5.931321e+19</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sun</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>5.294462e-04</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">315575</th>\n",
       "      <th>mars</th>\n",
       "      <td>-2.367681e+06</td>\n",
       "      <td>5.182832e+05</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mercury</th>\n",
       "      <td>-7.853682e+05</td>\n",
       "      <td>-4.787887e+06</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sat1</th>\n",
       "      <td>7.800000e+05</td>\n",
       "      <td>-5.931321e+19</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sun</th>\n",
       "      <td>1.691159e+01</td>\n",
       "      <td>-5.694637e+00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>venus</th>\n",
       "      <td>-2.404442e+06</td>\n",
       "      <td>2.555847e+06</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1893450 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            dis_x         dis_y  dis_z\n",
       "time_step body_name                                   \n",
       "1         earth      2.980000e+06 -5.931664e+01    0.0\n",
       "          mars       2.410000e+06 -2.555951e+01    0.0\n",
       "          mercury    4.740000e+06 -3.959744e+02    0.0\n",
       "          sat1       7.800000e+05 -5.931321e+19    0.0\n",
       "          sun        0.000000e+00  5.294462e-04    0.0\n",
       "...                           ...           ...    ...\n",
       "315575    mars      -2.367681e+06  5.182832e+05    0.0\n",
       "          mercury   -7.853682e+05 -4.787887e+06    0.0\n",
       "          sat1       7.800000e+05 -5.931321e+19    0.0\n",
       "          sun        1.691159e+01 -5.694637e+00    0.0\n",
       "          venus     -2.404442e+06  2.555847e+06    0.0\n",
       "\n",
       "[1893450 rows x 3 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Group by time step then body.\n",
    "a_ts_body_df = a_df.groupby(['time_step', 'body_name']).mean().sort_values(['time_step', 'body_name'])\n",
    "v_ts_body_df = v_df.groupby(['time_step', 'body_name']).mean().sort_values(['time_step', 'body_name'])\n",
    "p_ts_body_df = p_df.groupby(['time_step', 'body_name']).mean().sort_values(['time_step', 'body_name'])\n",
    "d_ts_body_df = d_df.groupby(['time_step', 'body_name']).mean().sort_values(['time_step', 'body_name'])\n",
    "# Group by body then time step.\n",
    "a_body_ts_df = a_df.groupby(['body_name', 'time_step']).mean().sort_values(['body_name', 'time_step'])\n",
    "v_body_ts_df = v_df.groupby(['body_name', 'time_step']).mean().sort_values(['body_name', 'time_step'])\n",
    "p_body_ts_df = p_df.groupby(['body_name', 'time_step']).mean().sort_values(['body_name', 'time_step'])\n",
    "d_body_ts_df = d_df.groupby(['body_name', 'time_step']).mean().sort_values(['body_name', 'time_step'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the size of each dimension in numpy array.\n",
    "# m-> the number of time steps in the simulation.\n",
    "# n-> the number of bodies in the simulation.\n",
    "# r-> number of dimensions in the vector holding the acceleration, displacement, etc.\n",
    "pos_m,pos_n,pos_r = x_raw.shape\n",
    "# Stack the XY or XYZ arrays of each body into columns, removing a dimension.\n",
    "# np.column_stack() -> takes a sequence of 1D arrays and stacks them as columns in a 2D matrix.\n",
    "# np.arange() provides evenly spaced values that repeat n times.  The new index.\n",
    "# \n",
    "pos_arr = np.column_stack(\n",
    "    (np.repeat(np.arange(pos_m),pos_n), \n",
    "     np.tile(np.arange(0,pos_n,1),pos_m), \n",
    "     x_raw.reshape(pos_m*pos_n,-1))\n",
    ")\n",
    "# Create dataframe from stacked column array.\n",
    "pos_df = pd.DataFrame(pos_arr)\n",
    "# Use df.groupby() to group by time step or planent and create MultiIndex for easy data referencing.\n",
    "pos_df = pos_df.groupby([0,1]).mean()\n",
    "pos_df.index.names = ['time_step', 'body']\n",
    "pos_df.columns = ['pos_x', 'pos_y']\n",
    "pos_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attempt to Display Position Data on Bokeh Scatter Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bokeh and plotting related imports\n",
    "# Plotting Imports\n",
    "import bokeh.io\n",
    "bokeh.io.output_notebook()  # Set plot output to embed in notebook.\n",
    "import bokeh.layouts\n",
    "import bokeh.plotting\n",
    "# Other imports for multi-plot figures.\n",
    "from bokeh.io import output_file, show\n",
    "from bokeh.layouts import column\n",
    "from bokeh.plotting import figure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need to create lists of numpy arrays that contain each body's position over time. \\\n",
    "List of arrays containing the positions of all bodies going back in time. = [bod1(x1, x2, x3, etc),(),()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of navigating Pandas MultiIndex to get X,Y position data.\n",
    "pos_df.loc[0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For shits and giggles.  Seeing how many indexing levels there are currently.\n",
    "pos_df.index.nlevels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How to index a Pandas dataframe with a multi-index.\n",
    "https://pandas.pydata.org/pandas-docs/stable/user_guide/advanced.html\n",
    "Great Stackoverflow summary on MultiIndex. https://stackoverflow.com/questions/53927460/select-rows-in-pandas-multiindex-dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Indexing to a specific column after navigating through the multiindex.\n",
    "pos_df.loc[(0,1), 'pos_x']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use slicing to get all time steps for each body.\n",
    "idx = pd.IndexSlice  # Need to create something called an indexer to kind of wrap the slice() function and make slicing easier.\n",
    "test_slice = pos_df.loc[idx[0:10, 0], 'pos_x']\n",
    "test_slice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shits and giggles.  Testing conversion of slice to numpy array.\n",
    "test_slice.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above was mostly getting used to using MultiIndex Pandas dataframes.  Now trying to create the list of arrays that will be used for plotting paths of each body."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Indexer to help with slicing dataframe.\n",
    "idx = pd.IndexSlice\n",
    "# List of bodies for each dimension whose elements are numpy arrays going back in time.  \n",
    "# Each element is a time series for that body and that body's dimension.\n",
    "pos_x_list = []\n",
    "pos_y_list = []\n",
    "# Group by level 1 to get the index of every body in the system.  Level 0 is the time step index.\n",
    "# Index will represent the body number we are currently extracting the position time series for.\n",
    "# Use slicing to get the position values for all time steps in a specified dimensions and save\n",
    "# to the list of numpy arrays for that dimension.\n",
    "for index, data in pos_df.groupby(level=1):\n",
    "    # Get slice of data to create time series of position values\n",
    "    # Use .to_numpy() to convert to numpy array\n",
    "    temp_x_time_series = pos_df.loc[idx[:, index], 'pos_x'].to_numpy()\n",
    "    temp_y_time_series = pos_df.loc[idx[:, index], 'pos_y'].to_numpy()\n",
    "    # Add time series to respective dimension.\n",
    "    pos_x_list.append(temp_x_time_series)\n",
    "    pos_y_list.append(temp_y_time_series)\n",
    "    \n",
    "# At this point, we now have a list of bodies for each position dimension that contains a time series \n",
    "# for that dimension and each body."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create functions to plot these lists of body time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bokeh.palettes import Turbo256 as palette\n",
    "import itertools\n",
    "from random import randint\n",
    "\n",
    "def plot_2D_body_time_series(pos_x_list, pos_y_list, plot_width, plot_height, title):\n",
    "    \"\"\"\n",
    "    Accepts lists for x and y dimensions whose elements are time series data and whose\n",
    "    index represents the number of the body in the simulation.\n",
    "    \n",
    "    returns Bokeh figure to plot.\n",
    "    \"\"\"\n",
    "    # Create Bokeh figure to add plots to\n",
    "    f = bokeh.plotting.figure(\n",
    "        title = title,\n",
    "        plot_width = plot_width,\n",
    "        plot_height = plot_height\n",
    "    )\n",
    "\n",
    "    # Generate line for each body.\n",
    "    # Randomly select color from palette using randint\n",
    "    for i in range(0,len(pos_x_list)):\n",
    "        f.line(\n",
    "            pos_x_list[i],\n",
    "            pos_y_list[i],\n",
    "            line_width = 1,\n",
    "            color = palette[randint(0,255)],\n",
    "            legend_label = str(i)\n",
    "        )\n",
    "    f.legend.location = 'top_left'\n",
    "    return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display body path plot\n",
    "fig = plot_2D_body_time_series(\n",
    "    pos_x_list = pos_x_list,\n",
    "    pos_y_list = pos_y_list,\n",
    "    plot_width = 800,\n",
    "    plot_height = 800,\n",
    "    title = \"Body Paths Over Time\"\n",
    ")\n",
    "\n",
    "bokeh.plotting.show(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate Displacement for n Time Steps on Each Body"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the number of time steps in the future to calculate displacement for.  This will add columns to the end of the displacement dataframe that will later be filled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the number of \"shotgun\" future time steps to predict.\n",
    "num_ts_to_predict = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make copy of position dataframe and add columns for displacment.\n",
    "dis_df = pos_df.copy(deep=True)\n",
    "# Add columns to end of displacement dataframe using for loop.\n",
    "for i in range(1,num_ts_to_predict+1):\n",
    "    col_title_x = \"dis_x_\" + str(i)\n",
    "    col_title_y = \"dis_y_\" + str(i)\n",
    "    dis_df[col_title_x] = None\n",
    "    dis_df[col_title_y] = None\n",
    "\n",
    "# Drop the previous position columns.\n",
    "dis_df.drop(['pos_x', 'pos_y'], axis=1, inplace=True)\n",
    "dis_df.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Will now loop over all time steps and future predicted time steps to calculate all displacements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Indexer to help with slicing dataframe.\n",
    "idx = pd.IndexSlice\n",
    "# Loop over all the time steps\n",
    "for curr_time_step in dis_df.index.levels[0]:\n",
    "    # Loop over the number of time steps in the future to be calculating\n",
    "    # displacement for.\n",
    "    # Don't do last time steps for displacement dataframe.  Can only look so many\n",
    "    # time steps into the future before running out of data.\n",
    "    if curr_time_step < (max(dis_df.index.levels[0]) - num_ts_to_predict):\n",
    "        for num_ts_in_future in range(1, num_ts_to_predict + 1):\n",
    "            col_title_x = \"dis_x_\" + str(num_ts_in_future)\n",
    "            col_title_y = \"dis_y_\" + str(num_ts_in_future)\n",
    "            dis_df.loc[idx[curr_time_step, :], [col_title_x, col_title_y]] = (\n",
    "                pos_df.loc[curr_time_step + num_ts_in_future] \n",
    "                - pos_df.loc[curr_time_step]\n",
    "            ).values\n",
    "\n",
    "# Drop the time steps that could not be used for calculating displacecment.\n",
    "# Create list of time steps to drop.\n",
    "beg_drop_index = max(dis_df.index.levels[0]) - num_ts_to_predict\n",
    "end_drop_index = max(dis_df.index.levels[0]) + 1\n",
    "drop_list = list(range(int(beg_drop_index), int(end_drop_index)))\n",
    "# Drop the time steps from the displacement dataframe.\n",
    "dis_df.drop(drop_list, level=0, inplace=True)\n",
    "# Ouput the new dataframe\n",
    "dis_df.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aggregate the Velocity Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need to aggregate the velocity data so we know what the velocity of each body was at each time step and what it should be at the future, predicted time steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct the velocity dataframe from the raw simulator velocity output data.\n",
    "# Get the size of each dimension in numpy array.\n",
    "# m-> the number of time steps in the simulation.\n",
    "# n-> the number of bodies in the simulation.\n",
    "# r-> number of dimensions in the vector holding the acceleration, displacement, etc.\n",
    "vel_m,vel_n,vel_r = v_raw.shape\n",
    "# Stack the XY or XYZ arrays of each body into columns, removing a dimension.\n",
    "# np.column_stack() -> takes a sequence of 1D arrays and stacks them as columns in a 2D matrix.\n",
    "# np.arange() provides evenly spaced values that repeat n times.  The new index.\n",
    "# \n",
    "vel_arr = np.column_stack(\n",
    "    (np.repeat(np.arange(vel_m),vel_n), \n",
    "     np.tile(np.arange(0,vel_n,1),vel_m), \n",
    "     v_raw.reshape(vel_m*vel_n,-1))\n",
    ")\n",
    "# Create dataframe from stacked column array.\n",
    "vel_df = pd.DataFrame(vel_arr)\n",
    "# Use df.groupby() to group by time step or planent and create MultiIndex for easy data referencing.\n",
    "vel_df = vel_df.groupby([0,1]).mean()\n",
    "vel_df.index.names = ['time_step', 'body']\n",
    "vel_df.columns = ['vel_x', 'vel_y']\n",
    "vel_df.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now need to add columns that will predict what the velocities will be in the future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add columns to end of velocity dataframe using for loop.\n",
    "for i in range(1,num_ts_to_predict+1):\n",
    "    col_title_x = \"vel_x_\" + str(i)\n",
    "    col_title_y = \"vel_y_\" + str(i)\n",
    "    vel_df[col_title_x] = None\n",
    "    vel_df[col_title_y] = None\n",
    "# Keeping velocities at respective time steps in place.\n",
    "vel_df.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can grab velocities from future time steps and add them to the new columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Indexer to help with slicing dataframe.\n",
    "idx = pd.IndexSlice\n",
    "# Loop over all the time steps\n",
    "for curr_time_step in vel_df.index.levels[0]:\n",
    "    # Loop over the number of time steps in the future to be grabbing\n",
    "    # velocities from.\n",
    "    # Don't do last time steps for displacement dataframe.  Can only look so many\n",
    "    # time steps into the future before running out of data.\n",
    "    if curr_time_step < (max(vel_df.index.levels[0]) - num_ts_to_predict):\n",
    "        for num_ts_in_future in range(1, num_ts_to_predict + 1):\n",
    "            col_title_x = \"vel_x_\" + str(num_ts_in_future)\n",
    "            col_title_y = \"vel_y_\" + str(num_ts_in_future)\n",
    "            vel_df.loc[idx[curr_time_step, :], [col_title_x, col_title_y]] = (\n",
    "                vel_df.loc[idx[curr_time_step + num_ts_in_future, :], ['vel_x','vel_y']]\n",
    "            ).values\n",
    "\n",
    "# Drop the time steps that could not be used for calculating displacecment.\n",
    "# Create list of time steps to drop.\n",
    "beg_drop_index = max(vel_df.index.levels[0]) - num_ts_to_predict\n",
    "end_drop_index = max(vel_df.index.levels[0]) + 1\n",
    "drop_list = list(range(int(beg_drop_index), int(end_drop_index)))\n",
    "# Drop the time steps from the displacement dataframe.\n",
    "vel_df.drop(drop_list, level=0, inplace=True)\n",
    "# Ouput the new dataframe\n",
    "vel_df.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, we have aggregated all the velocities for the future time steps we want to predict."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read In and Reformat Acceleration Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need to read in acceleration data to dataframe format so it is compatible for merging with all the other displacement, velocity, and mass data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct the acceleration dataframe from the raw simulator velocity output data.\n",
    "# Get the size of each dimension in numpy array.\n",
    "# m-> the number of time steps in the simulation.\n",
    "# n-> the number of bodies in the simulation.\n",
    "# r-> number of dimensions in the vector holding the acceleration, displacement, etc.\n",
    "acc_m,acc_n,acc_r = a_raw.shape\n",
    "# Stack the XY or XYZ arrays of each body into columns, removing a dimension.\n",
    "# np.column_stack() -> takes a sequence of 1D arrays and stacks them as columns in a 2D matrix.\n",
    "# np.arange() provides evenly spaced values that repeat n times.  The new index.\n",
    "# Had to add 1 to arange to go from 1 to 79 instead of 0.\n",
    "acc_arr = np.column_stack(\n",
    "    (np.repeat(np.arange(1, acc_m+1, 1),acc_n), \n",
    "     np.tile(np.arange(0,acc_n,1),acc_m), \n",
    "     a_raw.reshape(acc_m*acc_n,-1))\n",
    ")\n",
    "# Create dataframe from stacked column array.\n",
    "acc_df = pd.DataFrame(acc_arr)\n",
    "# Use df.groupby() to group by time step or planent and create MultiIndex for easy data referencing.\n",
    "acc_df = acc_df.groupby([0,1]).mean()\n",
    "acc_df.index.names = ['time_step', 'body']\n",
    "acc_df.columns = ['acc_x', 'acc_y']\n",
    "acc_df.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need to drop time steps that could not be used in previous dataframes since they went beyond the ability to calculate displacement for the time steps we want to predict. \\\n",
    "\n",
    "Need to keep in mind that there is no acceleration at time step 0.  Acceleration only exists after "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the time steps that could not be used for calculating displacecment.\n",
    "# Create list of time steps to drop.\n",
    "beg_drop_index = max(acc_df.index.levels[0]) - num_ts_to_predict\n",
    "end_drop_index = max(acc_df.index.levels[0]) + 1\n",
    "drop_list = list(range(int(beg_drop_index), int(end_drop_index)))\n",
    "# Drop the time steps from the displacement dataframe.\n",
    "acc_df.drop(drop_list, level=0, inplace=True)\n",
    "# Ouput the new dataframe\n",
    "acc_df.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read In and Reformat Mass Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mass data needs to be reformatted to fit the MultiIndex of the acceleration, velocity, and displacement dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_raw = m_raw.reshape(m_raw.shape[0])\n",
    "m_raw.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_raw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Will need to repeat array of body masses by the number of time steps and create the "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct the mass dataframe from the raw simulator mass output data.\n",
    "# Get the size of each dimension in numpy array.\n",
    "# m-> the number of time steps in the simulation.\n",
    "# n-> the number of bodies in the simulation.\n",
    "# r-> number of dimensions in the vector holding the acceleration, displacement, etc.\n",
    "mass_n = m_raw.shape[0]\n",
    "# Stack the Mass column with the indexing columns.  Mass column will be repeated by the number\n",
    "# of time steps.\n",
    "# np.column_stack() -> takes a sequence of 1D arrays and stacks them as columns in a 2D matrix.\n",
    "# np.arange() provides evenly spaced values that repeat n times.  The new index.\n",
    "# Using displacement dataframe dimensions to copy the masses enough.\n",
    "mass_arr = np.column_stack(\n",
    "     (np.repeat(np.arange(0, vel_m, 1),mass_n), \n",
    "     np.tile(np.arange(0,mass_n,1), vel_m),\n",
    "     np.tile(m_raw, vel_m))\n",
    ")\n",
    "# Create dataframe from stacked column array.\n",
    "mass_df = pd.DataFrame(mass_arr)\n",
    "# Use df.groupby() to group by time step or planent and create MultiIndex for easy data referencing.\n",
    "mass_df = mass_df.groupby([0,1]).mean()\n",
    "mass_df.index.names = ['time_step', 'body']\n",
    "mass_df.columns = ['mass']\n",
    "mass_df.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove the time steps not able to be calculated in displacement and velocity dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the time steps that could not be used for calculating displacecment.\n",
    "# Create list of time steps to drop.\n",
    "beg_drop_index = max(mass_df.index.levels[0]) - num_ts_to_predict\n",
    "end_drop_index = max(mass_df.index.levels[0]) + 1\n",
    "drop_list = list(range(int(beg_drop_index), int(end_drop_index)))\n",
    "# Drop the time steps from the displacement dataframe.\n",
    "mass_df.drop(drop_list, level=0, inplace=True)\n",
    "# Ouput the new dataframe\n",
    "mass_df.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge Mass, Acceleration, Velocity, and Displacement Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start with the mass and merge it with the acceleration dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data = mass_df.copy(deep=True)\n",
    "merged_data = pd.merge(merged_data, acc_df, left_index=True, right_index=True, how='outer')\n",
    "merged_data.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge in the velocity data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data = pd.merge(merged_data, vel_df, left_index=True, right_index=True, how='outer')\n",
    "merged_data.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge in the displacement data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data = pd.merge(merged_data, dis_df, left_index=True, right_index=True, how='outer')\n",
    "merged_data.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will rearrange columns to make the format easier to understand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create list of what the column order should be.\n",
    "cols = []\n",
    "cols.extend(['mass', 'acc_x', 'acc_y', 'vel_x', 'vel_y'])\n",
    "# Loop over all the time steps we wanted to predict and rearrange the columns\n",
    "# accordingly\n",
    "for i in range(1,num_ts_to_predict+1):\n",
    "    cols.append('dis_x_' + str(i))\n",
    "    cols.append('dis_y_' + str(i))\n",
    "    cols.append('vel_x_' + str(i))\n",
    "    cols.append('vel_y_' + str(i))\n",
    "# Rearrange columns using the create columns list.\n",
    "merged_data = merged_data[cols]\n",
    "# Drop the first time step for which there is no acceleration data.\n",
    "merged_data.drop(0, level=0, inplace=True)\n",
    "merged_data.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Body Time Series Data Format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create dataframe that has the time series associated with each body.  Should be able to just swap indexes around."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data_time_series = merged_data.copy(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data_time_series = merged_data_time_series.swaplevel('time_step', 'body').sort_index(level=0)\n",
    "merged_data_time_series.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attempt Converting Merged Datas to Numpy Arrays and Save as Both Pd dataframes and Np Arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data.to_numpy().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim0 = len(merged_data.index.get_level_values(0).unique())\n",
    "dim1 = len(merged_data.index.get_level_values(1).unique())\n",
    "dim2 = merged_data.shape[1]\n",
    "merged_data_ndarray = merged_data.to_numpy().reshape((dim0, dim1, dim2))\n",
    "merged_data_ndarray[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim0 = len(merged_data_time_series.index.get_level_values(0).unique())\n",
    "dim1 = len(merged_data_time_series.index.get_level_values(1).unique())\n",
    "dim2 = merged_data.shape[1]\n",
    "merged_data_time_series_ndarray = merged_data_time_series.to_numpy().reshape((dim0, dim1, dim2))\n",
    "merged_data_time_series_ndarray[0,5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the Numpy Arrays and Pandas Dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the output directory.\n",
    "out_dir = 'output/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the dataframes by pickling them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data.to_pickle(out_dir + 'sim_data_df-ts-body.pkl')\n",
    "merged_data_time_series.to_pickle(out_dir + 'sim_data_df-body-ts.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the dataframes to XLSX files to view in Excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data.to_excel(out_dir + 'sim_data_df-ts-body.xlsx')\n",
    "merged_data_time_series.to_excel(out_dir + 'sim_data_df-body-ts.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the numpy arrays by using numpy's saving function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(out_dir + 'sim_data_np-ts-body.npy', merged_data_ndarray)\n",
    "np.save(out_dir + 'sim_data_np-body-ts.npy', merged_data_time_series_ndarray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
